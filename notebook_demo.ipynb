{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBTK9brxkf19"
      },
      "outputs": [],
      "source": [
        "# notebook_demo.ipynb\n",
        "\n",
        "# ---\n",
        "# # Twitch Multimodal Demo\n",
        "#\n",
        "# This notebook demonstrates how to use the code in the \"my-twitch-multimodal\" repository.\n",
        "# ---\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 1) Imports from our local modules\n",
        "from data_utils import build_vocabulary, TwitchCommentDataset, my_collate_fn\n",
        "from data_utils import load_chat  # optional\n",
        "from preprocess import precompute_features\n",
        "from model import MultiModalLSTM\n",
        "from train import train_one_epoch\n",
        "from inference import generate_comment\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Example paths (adapt these to your folder structure)\n",
        "CHAT_FILE = \"data/chat.txt\"\n",
        "VIDEO_FILE = \"data/video.mp4\"\n",
        "AUDIO_FILE = \"data/audio.wav\"\n",
        "CACHE_DIR  = \"cached_features\"\n",
        "MODEL_PATH = \"my_multimodal_model.pth\"\n",
        "\n",
        "# 2) Build vocab (with special tokens)\n",
        "special_toks = [\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"]\n",
        "word2idx, idx2word = build_vocabulary(\n",
        "    chat_file=CHAT_FILE,\n",
        "    min_freq=1,\n",
        "    max_size=5000,\n",
        "    special_tokens=special_toks\n",
        ")\n",
        "print(\"Vocabulary size:\", len(word2idx))\n",
        "\n",
        "# 3) Precompute features (if not done yet)\n",
        "if not os.path.exists(CACHE_DIR):\n",
        "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "    precompute_features(\n",
        "        video_path=VIDEO_FILE,\n",
        "        audio_path=AUDIO_FILE,\n",
        "        chat_file=CHAT_FILE,\n",
        "        output_dir=CACHE_DIR\n",
        "    )\n",
        "\n",
        "# 4) Create the dataset/dataloader\n",
        "dataset = TwitchCommentDataset(\n",
        "    cache_dir=CACHE_DIR,\n",
        "    chat_file=CHAT_FILE,\n",
        "    word2idx=word2idx\n",
        ")\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    collate_fn=my_collate_fn,\n",
        ")\n",
        "\n",
        "# 5) Initialize model\n",
        "video_feature_dim = 3*224*224\n",
        "audio_feature_dim = 64\n",
        "vocab_size = len(word2idx)\n",
        "model = MultiModalLSTM(vocab_size, video_feature_dim, audio_feature_dim, hidden_dim=512).to(device)\n",
        "\n",
        "# 6) Train or load model\n",
        "train_model = True  # set to False to skip training\n",
        "\n",
        "if train_model:\n",
        "    # A simple training loop\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignoring <PAD>=0 if that's the scheme\n",
        "\n",
        "    for epoch in range(2):  # just 2 epochs for demo\n",
        "        loss_val = train_one_epoch(model, dataloader, optimizer, criterion, epoch+1, device)\n",
        "        print(f\"Epoch {epoch+1}, Loss={loss_val:.4f}\")\n",
        "\n",
        "    # save\n",
        "    torch.save(model.state_dict(), MODEL_PATH)\n",
        "    print(\"Saved model to:\", MODEL_PATH)\n",
        "else:\n",
        "    # load\n",
        "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
        "    model.load_state_dict(checkpoint)\n",
        "    print(\"Loaded model from:\", MODEL_PATH)\n",
        "\n",
        "# 7) Inference example\n",
        "sample = dataset[0]\n",
        "video_sample = sample['video']\n",
        "audio_sample = sample['audio']\n",
        "\n",
        "start_idx = word2idx.get(\"<SOS>\", 0)\n",
        "end_idx   = word2idx.get(\"<EOS>\", 0)\n",
        "\n",
        "gen_ids = generate_comment(\n",
        "    model=model,\n",
        "    video_tensor=video_sample,\n",
        "    audio_tensor=audio_sample,\n",
        "    start_token_idx=start_idx,\n",
        "    end_token_idx=end_idx,\n",
        "    max_len=20,\n",
        "    device=device,\n",
        "    temperature=0.8,\n",
        "    top_k=5\n",
        ")\n",
        "\n",
        "# Convert IDs to text\n",
        "rev_vocab = {v: k for k, v in word2idx.items()}\n",
        "decoded = [rev_vocab.get(tok_id, \"<UNK>\") for tok_id in gen_ids]\n",
        "print(\"Generated Comment:\", \" \".join(decoded))\n"
      ]
    }
  ]
}